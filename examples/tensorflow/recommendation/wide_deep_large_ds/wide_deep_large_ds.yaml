#
# Copyright (c) 2021 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

model:                                               # mandatory. lpot uses this model name and framework name to decide where to save tuning history and deploy yaml.
  name: wide_deep_large_ds
  framework: tensorflow                              # mandatory. supported values are tensorflow, pytorch, or mxnet; allow new framework backend extension.
  inputs: Placeholder,Placeholder_1,Placeholder_2,Placeholder_3,Placeholder_4,Placeholder_5,Placeholder_6,Placeholder_7,Placeholder_8,Placeholder_9,Placeholder_10,Placeholder_11,Placeholder_12,Placeholder_13,Placeholder_14,Placeholder_15,Placeholder_16,Placeholder_17,Placeholder_18,Placeholder_19,Placeholder_20,Placeholder_21,Placeholder_22,Placeholder_23,Placeholder_24,Placeholder_25,Placeholder_26,Placeholder_27,Placeholder_28,Placeholder_29,Placeholder_30,Placeholder_31,Placeholder_32,Placeholder_33,Placeholder_34,Placeholder_35,Placeholder_36,Placeholder_37,Placeholder_38
  outputs: head/predictions/probabilities     # optional. inputs and outputs fields are only required for tensorflow backend.

quantization:                                        # optional. tuning constraints on model-wise for advance user to reduce tuning space.
  calibration:
    sampling_size: 0                              # optional. default value is the size of whole dataset. used to set how many portions of calibration dataset is used. exclusive with iterations field.
  model_wise:                                        # optional. tuning constraints on model-wise for advance user to reduce tuning space.
    activation:
      algorithm: minmax
  op_wise: {
             'import/dnn/hiddenlayer_0/MatMul': {
               'activation':  {'dtype': ['uint8'], 'algorithm': ['minmax'], 'scheme':['asym']},
             }
           }

tuning:
  accuracy_criterion:
    relative:  0.01                                  # optional. default value is relative, other value is absolute. this example allows relative accuracy loss: 1%.
  exit_policy:
    timeout: 0                                       # optional. tuning timeout (seconds). default value is 0 which means early stop. combine with max_trials field to decide when to exit.
    max_trials: 100                                  # optional. max tune times. default value is 100. combine with timeout field to decide when to exit.
  random_seed: 9527                                  # optional. random seed for deterministic tuning.
